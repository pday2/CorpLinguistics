---
title: "Obama Speech Correspondence Analysis"
author: "Peter Day"
format:
  html:
    theme: journal
    toc: true
    code-link: true
    abstract-title: "Abstract"
  pdf:
    lof: true
    lot: true
    toc: true
    papersize: A4
echo: false
number-sections: true
warning: false
abstract: "Correspondence Analysis is investigated as a tool for differentiating whether a speech by Barack Obama was on national or international issues."
bibliography:
  - bibliography.bib
  - packages.bib
csl: unified-style-sheet-for-linguistics.csl
#prefer-html: true
---

```{r}
#| label: setup
#| include: false
# insert code chunk Ctrl-Alt-i
rm(list = ls())
library("MASS")
library("here") # I hope this works, I had great difficulties working with here
library("tidyverse")
library("dplyr")
library("mclm")
library("kableExtra")
library("syuzhet") # Sentiment Analysis
library("ggplot2")
library("ROCR") # ROC plots


knitr::write_bib(
  c("base", "mclm", "tidyverse", "ggplot2", "kableExtra", "syuzhet", "MASS", "ROCR"),
  here("packages.bib")
)
# An Introduction to Statistical Learning with Applications in R Second Edition

options(digits = 3, knitr.kable.NA = "")
corpus_folder <- here::here("DataUCSB")
obama_fnames <- get_fnames(corpus_folder)
short_fnames <- short_names(obama_fnames)
sub_corp <- re_retrieve_first(obama_fnames, "/DataUCSB/([^/]+)", requested_group = 1)
```

# Introduction

Barack Obama, the 44th President of The United States, was well known for his memorable speeches. This paper analyzes about 130 of his speeches using the multivariate statistical technique known as correspondence analysis (CA) using the base R function ca [@R-base]. CA is a dimension reduction technique which may also be used to view associations between categorical variables via biplots using `{ggplot2}` [@R-ggplot2]. 

The speeches were separated into three topic categories: national, international and State of The Union (sotu). The two largest categories, by speech count, are national and international and reflect whether the main topic of the speech covers issues relating to national or international interests.   The yearly State of The Union speech is a long speech summarizing the previous year and setting goals for the future and covers issues of both national and international issues. CA is investigated as a technique for differentiating between the various categories of speeches.

In this case it is expected that there will be overlap between the categories of speeches. For example, a speech about the United States military fighting terrorism in Afghanistan will cover both national and international issues. Speeches about global warming may talk about how national policy effects the environment at a global scale. Likewise, the State of The Union speeches cover a broad range of topics and it may be difficult to discern these from the other topic categories. This of course leads to a problem with this study and that is the categorization of the speeches. The national and international speeches were manually categorized, and required some subjective judgement.

Speeches were scraped from [UC Santa Barbara's The American Presidency Project](https://www.presidency.ucsb.edu/documents/barack-obama-event-timeline) @ucsb using a Python program employing the BeautifulSoup package. Roughly 130 speeches were collected, as given by Barack Obama starting with his nomination for Democratic party candidate. Each file has one speech and is an un-annotated text file. The speeches have been separated into three directories, one each for national, international and State of The Union speeches. There are 80 national speeches, 44 international and seven State of The Union speeches.

Four different word lists were investigated ascertain which is most effective at differentiating between the speech types. First is a list of content words which is automatically populated after removing stop words from the speeches. Next, a manually defined list of content words which were selected from words generated by a Latent Dirichlet Allocation from a previous topic modeling study. Third, a list of function words, mostly prepositions and lastly a list of the most frequent bigrams.

# Correspondence Analysis

Correspondence analysis (CA), is a statistical dimension reduction technique. @petrovic2009textual In reducing a data set with many dimensions down to only two dimensions, it is also useful for visualizing multivariate data on a 2-dimensional plot, or biplot. In this case, the data are comprised of documents, or speeches, as rows and the columns are words of interest. Four sets of words are investigated to determine if one set performs best at differentiating between speech topics. CA is similar to principle components analysis, which is another multivariate technique for dimension reduction of continuous data. CA is used for discrete data, such as counts in a contingency table. The contingency table is created, along with a word frequency list, functions from the `{mclm}` library [@R-mclm]. In this case the data are counts of words in speeches. CA explores whether the observed counts in the table are different than would be expected if the variables, speeches and words, were independent. A measurement of independence for the data is the Pearson Chi-square test. However, one condition for this test is that no more than 20% of the expected table values can be less than 5. With data, such as this, many observed counts are very low, as few of the words will have high counts in any particular speech. In the case of the automated content words using the stop list to remove common and trivial words, the percentage of cells with an expected value less than five is about 87%. Thus, the results of the Chi-square test may not be accurate. @theory_ca

In CA, total inertia is a measurement of the variation observed in the contingency table. CA is computed using singular value decomposition on the contingency table, which returns eigenvalues and an eigenvector. The eigenvalues can be explained as the correlation between the two variables, in this case, speeches and words. The sum of the eigenvalues is the total inertia of the data. Thus, each dimension in the decomposition contributes to the total amount of inertia. When reducing the data to two dimensions for visualization, the more inertia that is explained by these two dimension, the better the total inertia of the data is explained.

A biplot is a plotting of two of the reduced dimensions as a scatter plot. Most usually, the first two dimensions, explaining the most inertia of any two dimensions are used, as to best represent the observed data. This data investigates speeches and words found in those speeches. The closer two speeches are to each other on the biplot, the more similar they are in terms of word usage. The closer two words are to each other on the biplot, the more speeches they have in common. And lastly, the closer a speech is to a word, the more often that words occurs in that speech than would be expected under independence.

Extensive use of `{tidyverse}` [@R-tidyverse] for data wrangling and `{kableExtra}` [@R-kableExtra] for pretty tables can be found throughout the paper. `{syuzhet}` [@R-syuzhet] is used for sentiment analysis and `{ROCR}` [@R-ROCR]is used for ROC curve plots.

# Biplots

I start this study by making four sets of biplots, one for each of the word sets: 




```{r}
# Create Frequency List
# This one is a little slow, but not too bad
flist <- freqlist(obama_fnames) 
# print(flist, n = 5)
```

<!-- ######################### Functions ############################## -->

```{r}
compile_frequencies <- function(features,
                                fnames,
                                short_fnames,
                                ...) {
  d <- map(setNames(fnames, short_fnames), function(fname) {
    freqlist(fname, ...)[features]
  }) %>%
    bind_cols() %>% 
    data.frame(row.names = features) %>% 
    as.matrix() %>% 
    t() %>% 
    drop_empty_rc()
  return(d)
}
```

```{r}
get_coords <- function(d_ca, sub_corp) {
  texts_df <- row_pcoord(d_ca)[,c(1, 2)] %>% 
    as_tibble(rownames = "text") %>% 
    mutate(Subcorpus = sub_corp)
  
  words_df <- col_pcoord(d_ca)[,c(1, 2)] %>% 
    as_tibble(rownames = "word")
  
  ret <- list(
    rows = texts_df,
    cols = words_df
  )
  return(ret)
}
```

```{r}
plot_ca <- function(ca_coords, variances, titlelabel) {
  dim_1 <- sprintf("Dimension 1 (%.2f %%)", variances[[1]])
  dim_2 <- sprintf("Dimension 2 (%.2f %%)", variances[[2]])
  
  ggplot(ca_coords$cols, aes(x = V1, y = V2)) +
    geom_text(aes(label = word), color = "gray60") +
    geom_point(data = ca_coords$rows, aes(color = Subcorpus)) +
    scale_color_manual(values = c("#0072B2", "#E69F00","#FC4E07")) +
    geom_hline(yintercept = 0, color = "darkgray") +
    geom_vline(xintercept = 0, color = "darkgray") +
    theme_bw(base_size = 12) +
    labs(x = dim_1, y = dim_2) +
    ggtitle(titlelabel) +
    coord_fixed()
}
```

 
<!--              Stop List generated content words                    -->

```{r}
#| label: fig-slbiplots
#| fig-cap: Biplots for stop list generated features
#| fig-subcap:
#|    - "Full plot"
#|    - "Zoom on area of interest"
#| layout-ncol: 2
# Content words as features ----
# Larger Kaggle stop word list
stop_list <- read_types(here::here("assets", "kaggle_stopwords.txt"))
features_sl <- freqlist(obama_fnames) %>% drop_types(stop_list) %>%
  keep_pos(1:150) %>% as_types()

d_sl <- compile_frequencies(features_sl, obama_fnames, short_fnames)
d_ca_sl <- ca(d_sl)
sumry_sl <- summary(d_ca_sl)
ca_coords_sl <- get_coords(d_ca_sl, sub_corp)
par(mfrow = c(1, 2))
plot_ca(ca_coords_sl, summary(d_ca_sl)$scree[,3], 'Stop List')
plot_ca(ca_coords_sl, summary(d_ca_sl)$scree[,3], 'Stop List') +
  coord_fixed(xlim = c(-0.5, 0.6), ylim = c(-0.5, 0.7))
```



```{r}

```
The stop word list used to generate the content words, was downloaded from Kaggle and has about 700 words [@kaggle]. @fig-slbiplots shows some reasonable separation, but not great, between the national and international speeches. As expected the State of The Union speeches are inter-mixed, leaning more towards national speeches.


```{r}
texts_df_sl <- row_pcoord(d_ca_sl)[,c(1, 2)] %>% 
  as_tibble(rownames = "text") %>% 
  mutate(Subcorpus = sub_corp)
words_df_sl <- col_pcoord(d_ca_sl)[,c(1, 2)] %>% 
  as_tibble(rownames = "word")
```

<!-- Proportion of cells with expected value less than five. -->

```{r}
#| include: false
c2 <- chisq.test(d_sl)
# count number of cell with expected count less than 5
count=0
for (i in 1:nrow(d_sl)){
  for (j in 1:ncol(d_sl)){
    if (c2$expected[i,j]<5){
      count = count + 1
    }
  }
}
# proportion of cells with expected value less than 5
count/(nrow(d_sl)*ncol(d_sl))
```


<!--                       Function Words                         -->

```{r}
#| label: fig-fwbiplots
#| fig-cap: Biplots for function words as features
#| fig-subcap:
#|    - "Full plot"
#|    - "Zoom on area of interest"
#| layout-ncol: 2
# Functions words - mostly prepositions
features_fw <- read_types(here::here("assets", "function-words.txt"))
d_fw <- compile_frequencies(features_fw, obama_fnames, short_fnames)
d_ca_fw <- ca(d_fw)
sumry_fw <- summary(d_ca_fw)
ca_coords_fw <- get_coords(d_ca_fw, sub_corp)
par(mfrow = c(1, 2))
plot_ca(ca_coords_fw, summary(d_ca_fw)$scree[,3], 'Function Words')
plot_ca(ca_coords_fw, summary(d_ca_fw)$scree[,3], 'Function Words') +
  coord_fixed(xlim = c(-0.75, 0.5), ylim = c(-0.5, 0.5))
```

Using function words as features, as shown in @fig-fwbiplots, leads to more overlap between the two main categories of speeches. This method, in this case, leads to poor differentiating between the main issues of the speeches.

```{r}
texts_df_fw <- row_pcoord(d_ca_fw)[,c(1, 2)] %>% 
  as_tibble(rownames = "text") %>% 
  mutate(Subcorpus = sub_corp)
words_df_fw <- col_pcoord(d_ca_fw)[,c(1, 2)] %>% 
  as_tibble(rownames = "word")
```

<!--              Content Words from Topic Modeling                    -->

```{r}
#| label: fig-cwbiplots
#| fig-cap: Biplots for topic modeling generated content words as features
#| fig-subcap:
#|    - "Full plot"
#|    - "Zoom on area of interest"
#| layout-ncol: 2
# User defined content word list from Python topic modeling analysis
features_cw <- read_types(here::here("assets", "content-words.txt"))
d_cw <- compile_frequencies(features_cw, obama_fnames, short_fnames)
d_ca_cw <- ca(d_cw)
sumry_cw <- summary(d_ca_cw)
ca_coords_cw <- get_coords(d_ca_cw, sub_corp)
par(mfrow = c(1, 2))
plot_ca(ca_coords_cw, summary(d_ca_cw)$scree[,3], 'Content Words')
plot_ca(ca_coords_cw, summary(d_ca_cw)$scree[,3], 'Content Words') +
  coord_fixed(xlim = c(-1.25, 1.0), ylim = c(-1.0, 0.25))
```

The topic modeling generated list of content words is looking to be quite promising at distinguishing the main speech topics on a correspondence analysis generated biplot, see @fig-cwbiplots. The State of the Union speeches are firmly within the national speeches boundaries, but there is little overlap and thus good separation with the international speeches.

```{r}
texts_df_cw <- row_pcoord(d_ca_cw)[,c(1, 2)] %>% 
  as_tibble(rownames = "text") %>% 
  mutate(Subcorpus = sub_corp)
words_df_cw <- col_pcoord(d_ca_cw)[,c(1, 2)] %>% 
  as_tibble(rownames = "word")
```


```{r}
# National Words
nat.words <- words_df_cw %>%
  filter(V1 > -0.25 & V2 > -0.4) %>% 
  mutate(dist_to_center = sqrt((V1+0.25)^2 + V2^2)) %>% 
  arrange(desc(dist_to_center)) %>% 
  head(10) %>% 
  pull(word)
```


```{r}
# International Words
int.words <- words_df_cw %>%
  filter(V1 < -0.25 & V2 < 0.1 ) %>% 
  mutate(dist_to_center = sqrt((V1)^2 + V2^2)) %>% 
  arrange(desc(dist_to_center)) %>% 
  head(10) %>% 
  pull(word)
```

The top ten words most associated with national and international speeches, see @tbl-infl, when using the content word list. These are the words with the greatest influence on determining whether a speech is on national or international issues.

```{r}
#| label: tbl-infl
#| tbl-cap: Most influential words for each topic
tab <- t(matrix(c(nat.words, int.words), nrow=2, byrow=TRUE))
kbl(tab, booktabs = TRUE,col.names = c("Naitonal", "International")) %>% 
  kable_paper() %>% 
  kable_styling(latex_options = "striped")
```




<!--                              Bigrams                                -->

```{r}
#| label: fig-bibiplots
#| fig-cap: Biplots for bigrams as features
# Bigrams as features ----
features_bi <- obama_fnames %>%
  freqlist(ngram_size = 2) %>%
  keep_bool(ranks(.) <= 150) %>%
  as_types()

d_bi <- compile_frequencies(features_bi, obama_fnames, short_fnames, ngram_size = 2)
d_ca_bi <- ca(d_bi)
sumry_bi <- summary(d_ca_bi)
ca_coords_bi <- get_coords(d_ca_bi, sub_corp)
# plot_ca(ca_coords_bi, summary(d_ca_bi)$scree[,3], 'Bigrams')
par(mfrow = c(1, 1))
plot_ca(ca_coords_bi, summary(d_ca_bi)$scree[,3], 'Bigrams') +
  coord_fixed(xlim = c(-1.0, 0.5), ylim = c(-0.75, 0.6))
```


Looking at the various plots, it appears that using content words for features generates the first two dimensions with the greatest separation between national and international speeches. Perhaps, followed by the stop list generated list of words. This separation will be looked at more closely. As seen in @fig-bibiplots, separation between the topics using the most frequent bigrams is quite poor at distinguishing speech types. Perhaps, this is due to bigrams being very common phrases, such as "a lot" or "about the", which will occur in both national and international speeches.

```{r}
texts_df_bi <- row_pcoord(d_ca_bi)[,c(1, 2)] %>% 
  as_tibble(rownames = "text") %>% 
  mutate(Subcorpus = sub_corp)
words_df_bi <- col_pcoord(d_ca_bi)[,c(1, 2)] %>% 
  as_tibble(rownames = "word")
```

<!-- Trigrams errors out and doesn't work -->
<!-- not sure how I would fix this without seriously messing with the data set -->

```{r}
# Trigrams as features ----
features_tr <- obama_fnames %>%
  freqlist(ngram_size = 3) %>%
  keep_bool(ranks(.) <= 150) %>%
  as_types()
# ! Problem while computing `Subcorpus = sub_corp`.
# ✖ `Subcorpus` must be size 131 or 1, not 133.
```

<!--                  Sentiment Analysis                  -->

# Sentiment Analysis

Sentiment analysis is briefly explored to determine if there is a pattern in the biplot data. Sentiment analysis, on a simple level, scores each word as having a negative to positive connotation. A completely negative word receives a score of -1, a postive word +1, and neutral words are around 0. The score for a whole document or speech is an average of all the individual scores in that document. The speeches on the biplot are then colored according to that speech's sentiment. The get_sentiment function from the syuzhet library scores on a sentence by sentence basis, taking context into account, such as negations and sarcasm [@R-syuzhet]. Of course, a look into sentiment analysis could be a whole paper itself, and is thus only briefly considered here.

```{r}
######################### SENTIMENT ###################################
texts_df_cw$senti <- 0
texts_df_cw$senti <-as.double(texts_df_cw$senti)
for (i in 1: length(obama_fnames))
{
  text <- read_txt(obama_fnames[i], file_encoding = "UTF-8", line_glue = NA)
  vector <- strsplit(text, "(?<=\\.|\\?)\\s(?=[A-Z])", perl = TRUE)[[1]]
  texts_df_cw$senti[i] <- mean(get_sentiment(vector))
}

#summary(texts_df_cw$senti)
#head(texts_df_cw)
#length(texts_df_cw$senti)
```

```{r}
# extract % number for dimension 
dim_1_cw <- sprintf("Dimension 1 (%.2f %%)", summary(d_ca_cw)$scree[1,3])
dim_2_cw <- sprintf("Dimension 2 (%.2f %%)", summary(d_ca_cw)$scree[2,3])
```


```{r}
#| label: fig-sentiment1
#| fig-cap: Sentiment scores on the content word biplot
# PLOT TEXT NAMES colored by sentiment
# TEXT NAMES COLORED BY SENTIMENT
par(mfrow = c(1, 1))
ggplot(texts_df_cw, aes(x = V1, y = V2)) +
  geom_label(aes(label=text,fill = senti), color="white", fontface = "bold") +
  scale_fill_gradient(low = "blue", high = "orange") +
  geom_hline(yintercept = 0, color = "darkgray") +
  geom_vline(xintercept = 0, color = "darkgray") +
  theme_bw(base_size = 12) +
  labs(x = dim_1_cw, y = dim_2_cw) +
  xlim(-1.0, 0.6) +
  ylim(-0.3, 0.3) +
  ggtitle('Sentiment Scores for Speeches based on the Content Word list') + 
  coord_fixed()
```

## Look at speeches with extreme sentiment values

```{r}
#| include: false
texts_df_cw %>% filter(senti>2.5)
```

There is one speech with a sentiment score greater than 2.5. Statement3n has a score of 3.24, by far the highest score. Statement3n is concerning a ruling by the Supreme Court which holds "that state regulation of abortion may not place an “undue burden” on women exercising their right to an abortion," in which Obama compliments the courts decision. 



```{r}
#| include: false
texts_df_cw %>% filter(senti<(-0.2))
```
There are two speeches with scores less than -0.2, statement23i with a score of -0.275 and statement32n with a score of -0.336. Statement32n is a comment about a law for fair sentencing of drug users and statement23i and how some people were unfairly sentenced using old and unjust laws. Statement23i is a condemnation of the shooting at Charlie Hebdo magazine offices in Paris.


```{r}
#| label: fig-sentiment2
#| fig-cap: Sentiment scores with the content words
par(mfrow = c(1, 1))
ggplot(words_df_cw, aes(x = V1, y = V2)) +
  geom_text(aes(label = word), color = "gray60") +
  geom_point(data = texts_df_cw, aes(x = V1, y = V2, color=senti), size=3) +
  scale_color_gradient(low = "blue", high = "orange") +
  geom_hline(yintercept = 0, color = "darkgray") +
  geom_vline(xintercept = 0, color = "darkgray") +
  theme_bw(base_size = 12) +
  labs(x = dim_1_cw, y = dim_2_cw) +
  xlim(-1.0, 1.0) +
  ylim(-0.5, 0.25) +
  ggtitle('Sentiment Scores for Speeches based on Content Word list') +
  coord_fixed()
```
From the first plot, see @fig-sentiment1, there does not appear to be a pattern in the sentiment scores of Obama speeches. The scoring seems to be fairly random. The second plot, @fig-sentiment2, shows words, in one case such as "war" near a low sentiment speech, however this is not always the case. Another speech with a negative score has the words "audience" and "everybody" nearby, neither of which are negative words on their own, without looking at context.

```{r}
#| label: tbl-avgsent
#| tbl-cap: Average sentiment for each subcorpus
avg.sent <- texts_df_cw %>% 
  group_by(Subcorpus) %>% 
  summarise(avg_sentiment = mean(senti))
kbl(avg.sent, booktabs = TRUE) %>% 
  kable_paper() %>% 
  kable_styling(latex_options = "striped")
```

@tbl-avgsent shows the average sentiment score by sub-corpus. Even though no pattern was visible on the biplot, the table shows some variation in sentiment in each of the sub-corpora.

<!-- Look at distance from mean national coordinates to mean international coordinates -->

# Distance

In trying to determine which method, of the four, is best for differentiating between national and international speeches, I first look at the distance between the centroids for each type of speech. This however, does not say anything about variance or overlap, that is, say, national speeches in an area which is mostly international.

```{r}
cw <- texts_df_cw %>% 
  filter(Subcorpus != 'sotu') %>% 
  group_by(Subcorpus) %>% 
  summarise(avg_V1 = mean(V1), avg_V2=mean(V2), sd_V1 = sd(V1), sd_V2=sd(V2)) 
fw <- texts_df_fw %>% 
  filter(Subcorpus != 'sotu') %>% 
  group_by(Subcorpus) %>% 
  summarise(avg_V1 = mean(V1), avg_V2=mean(V2), sd_V1 = sd(V1), sd_V2=sd(V2))
sl <- texts_df_sl %>% 
  filter(Subcorpus != 'sotu') %>% 
  group_by(Subcorpus) %>% 
  summarise(avg_V1 = mean(V1), avg_V2=mean(V2), sd_V1 = sd(V1), sd_V2=sd(V2))
bi <- texts_df_bi %>% 
  filter(Subcorpus != 'sotu') %>% 
  group_by(Subcorpus) %>% 
  summarise(avg_V1 = mean(V1), avg_V2=mean(V2), sd_V1 = sd(V1), sd_V2=sd(V2))
```


```{r}
dat2 <- bind_rows(lst(cw, fw, sl, bi), .id='id')
dat2 <- dat2 %>% mutate(topic = substr(Subcorpus, 1, 3) )
```

```{r}
dat2a <- dat2 %>% filter(topic == "int") %>% mutate(x1=avg_V1, y1=avg_V2)
dat2a <- full_join(dat2a, dat2 %>% filter(topic == "nat") %>% mutate(x2=avg_V1, y2=avg_V2),by="id")
dat3 <- dat2a %>% dplyr::select(id, x1, y1, x2, y2)
```


```{r}
dat <- inner_join(dat2, dat3, by="id")
dat <- dat %>% mutate(distance=round(sqrt((x2-x1)^2+(y2-y1)^2),3))
dat <- dat %>% mutate(avg_x=(x2+x1)/4, avg_y=(y2+y1)/4)
```

```{r}
#| label: fig-distance
#| fig-cap: Distance between national and international centroids for each feature method.
par(mfrow = c(1, 1))
ggplot(dat, aes(color=id, shape = topic)) +
  geom_point(aes(x = avg_V1, y = avg_V2), size=3) +
  geom_segment(aes(x=x1,xend=x2,y=y1,yend=y2, color=id)) +
  geom_label(aes(x=x1+0.05, y=y1+0.03,label=distance)) +
  geom_label(aes(x=x1+0.06, y=y1-0.02,label=id)) +
  coord_fixed()
```

Using the topic modeling generated content word speeches for correspondence analysis leads to the largest distance between the centroids for national and international speeches, as seen in @fig-distance, followed closely by the stop list generated content word list. Using a content word list, of some sort, would seem to be leading the methods at differentiating between speech topics. 

<!--                                Inertia                              -->
# Inertia

As mentioned earlier, inertia is similar to variance explained in principle components analysis. The first two components of the correspondence analysis output using the function word list results in the most inertia explained at 27.6%, see @tbl-cperc. Thus, if the goal was to recreate as much inertia of the observed data in only two dimensions, the function word list should be used. This doesn't, however, say anything about the goodness of the differentiating power of each method.

```{r}
#| label: tbl-cperc
#| tbl-cap: Inertia cummulative percent
# dim    value      %   cum%
to_tib <- function(d_ca) {
  s <- summary(d_ca)$scree[1:2,]
  colnames(s) <- c("dim", "value", "percent", "cum_percent")
  return(s %>% as_tibble)
}
sl.s <- to_tib(d_ca_sl)
bi.s <- to_tib(d_ca_bi)
cw.s <- to_tib(d_ca_cw)
fw.s <- to_tib(d_ca_fw)

summary_table <- bind_rows(lst(sl.s, cw.s, fw.s, bi.s), .id='id')
kbl(summary_table, booktabs = TRUE) %>% 
  kable_paper() %>% 
  kable_styling(latex_options = "striped")
```

# Logistic Regression

I decided to use logistic regression as a means to determine which method was best at separating nationally themed speeches from international ones. The reasoning being, there must be some separation to be able to accurately predict the topic using logistic regression. If the topics were completely interspersed it would be quite difficult to predict which topic a speech is. I regressed the observed topic on V1 and V2, the first two components from the correspondence analysis, leaving out State of The Union speeches. I then predicted the topic for each of the four methods, and used the ROC curve to find the optimal threshold to convert the logistic probability into a categorical variable. @lr_threshold This method sets the threshold of the probability to the value at which the ROC curve is closest to the (0,1) point, see @fig-ROCcurves. The ROC curve function comes from the R library ROCR [@R-ROCR]. The total number of correctly predicted topics was summed and an overall percentage found for each method. Doing this, I found that the topic modeling generated content word list was best at predicting the topic at 90.3%, as shown in @tbl-percent and is thus would be the best for differentiating between national and international speeches.

```{r}
# Make dummy variable for Subcorpus where national = 0, international = 1
cw_top <- texts_df_cw %>% filter(Subcorpus != 'sotu') %>% mutate(topic = ifelse(Subcorpus=='national', 0, 1))
fw_top <- texts_df_fw %>% filter(Subcorpus != 'sotu') %>% mutate(topic = ifelse(Subcorpus=='national', 0, 1))
sl_top <- texts_df_sl %>% filter(Subcorpus != 'sotu') %>% mutate(topic = ifelse(Subcorpus=='national', 0, 1))
bi_top <- texts_df_bi %>% filter(Subcorpus != 'sotu') %>% mutate(topic = ifelse(Subcorpus=='national', 0, 1))
```


```{r}
# Logistic regression model for topic based on V1 and V2
cw_lr <- glm(topic~V1+V2, data = cw_top, family = 'binomial')
fw_lr <- glm(topic~V1+V2, data = fw_top, family = 'binomial')
sl_lr <- glm(topic~V1+V2, data = sl_top, family = 'binomial')
bi_lr <- glm(topic~V1+V2, data = bi_top, family = 'binomial')
```


```{r}
# Predict topic for each model
#               predict(model, data)
predicted_cw <- predict(cw_lr, cw_top, type="response")
predicted_fw <- predict(fw_lr, fw_top, type="response")
predicted_sl <- predict(sl_lr, sl_top, type="response")
predicted_bi <- predict(bi_lr, bi_top, type="response")
# Returns a value between 0 and 1, need to find optimal threshold to split 
# into 0 or 1 values
```



```{r}
#| label: fig-ROCcurves
#| fig-cap: ROC curves
#| fig-subcap:
#|    - "Content words"
#|    - "Function words"
#|    - "Stop list"
#|    - "Bigrams"
#| layout-nrow: 2
# Use point closest to (0,0) on ROC curve for threshold for topic predictions
# https://www.theissaclee.com/post/logistic-regression-beta/
rocplot <- function (predicted, truth, titletext, ...) {
  prediction(predicted, truth) %>%
    performance(measure = "tpr", x.measure = "fpr") -> result
  plotdata <- data.frame(x = result@x.values[[1]],
                         y = result@y.values[[1]], 
                         p = result@alpha.values[[1]])
  
  p <- ggplot(data = plotdata) +
    geom_path(aes(x = x, y = y)) + 
    xlab(result@x.name) +
    ylab(result@y.name) +
    theme_bw() +
    ggtitle(titletext)
  
  dist_vec <- plotdata$x^2 + (1 - plotdata$y)^2
  opt_pos <- which.min(dist_vec)
  
  p + 
    geom_point(data = plotdata[opt_pos, ], 
               aes(x = x, y = y), col = "red") +
    annotate("text", 
             x = plotdata[opt_pos, ]$x + 0.1,
             y = plotdata[opt_pos, ]$y,
             label = paste("p =", round(plotdata[opt_pos, ]$p, 3)))
}
par(mfrow = c(2, 2))
rocplot(predicted_cw, cw_top$topic, "CW") # 0.433
rocplot(predicted_fw, fw_top$topic, "FW") # 0.375
rocplot(predicted_sl, sl_top$topic, "SL") # 0.330
rocplot(predicted_bi, bi_top$topic, "Bi") # 0.474
par(mfrow = c(1, 1))
```


```{r}
# pred is prediction using threshold from ROC curve
cw_top <- cw_top %>% mutate(pred = ifelse(predict(cw_lr, cw_top, type="response")>0.433, 1, 0))
fw_top <- fw_top %>% mutate(pred = ifelse(predict(fw_lr, fw_top, type="response")>0.375, 1, 0))
sl_top <- sl_top %>% mutate(pred = ifelse(predict(sl_lr, sl_top, type="response")>0.330, 1, 0))
bi_top <- bi_top %>% mutate(pred = ifelse(predict(bi_lr, bi_top, type="response")>0.474, 1, 0))
```

```{r}
# Percent of predictions not equal to topic
cw.perc <- cw_top %>% 
  mutate(different = ifelse(topic==pred, 1, 0)) %>% 
  summarise(cw.percent=sum(different/124))
fw.perc <- fw_top %>% 
  mutate(different = ifelse(topic==pred, 1, 0)) %>% 
  summarise(fw.percent=sum(different/124))
sl.perc <- sl_top %>% 
  mutate(different = ifelse(topic==pred, 1, 0)) %>% 
  summarise(sl.percent=sum(different/124))
bi.perc <- bi_top %>% 
  mutate(different = ifelse(topic==pred, 1, 0)) %>% 
  summarise(bi.percent=sum(different/124))
```

```{r}
#| label: tbl-percent
#| tbl-cap: Logistic regression Prediction percent correct
col1 <- c('Content Words', 'Function Words', 'Stop List', 'Bigrams')
col2 <- c(round(as.numeric(cw.perc), 3), 
          round(as.numeric(fw.perc), 3), 
          round(as.numeric(sl.perc), 3), 
          round(as.numeric(bi.perc), 3))
tabl <- t(matrix(c(col1, col2), nrow=2, byrow=TRUE))
kbl(tabl, booktabs = TRUE,col.names = c("Method", "Percent Correct")) %>% 
  kable_paper() %>% 
  kable_styling(latex_options = "striped")
```


# Conclusion

Correspondence Analysis was investigated as a technique for determining the topic of a corpus of Barack Obama speeches. Four different word lists were used as features for the analysis and the results analyzed with logistic regression. The word list based on a previous topic modeling to generate content words yielded the best results for separating the categories of speeches on a two dimensional plane.

`r if (!knitr::is_html_output()) "# References {.unnumbered}"`